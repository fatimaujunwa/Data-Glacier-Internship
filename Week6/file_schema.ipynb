{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71489d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "from dask import dataframe as dask\n",
    "import ray as r\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "import gzip\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46454253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3258"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = \n",
    "# gender_submission.csv\n",
    "# os.path.getsize('gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f2ca1",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94d5ac",
   "metadata": {},
   "source": [
    "#### With Modlin and Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad3d48ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 11:17:29,407\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read:  0.009287834167480469 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r.shutdown()\n",
    "r.init()\n",
    "start = time.time()\n",
    "df = pd.read_csv('gender_submission.csv')\n",
    "begin = time.time()\n",
    "print(\"Time taken to read: \",(begin-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189c02e",
   "metadata": {},
   "source": [
    "#### With Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4cdc7716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read:  134.20073699951172 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "begin = time.time()\n",
    "dask_data = dask.read_csv('gender_submission.csv')\n",
    "end = time.time()\n",
    "print(\"Time taken to read: \",(begin-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d99fb",
   "metadata": {},
   "source": [
    "#### With Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24c54e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read:  136.75519514083862 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "begin = time.time()\n",
    "pandas_data = pd.read_csv('gender_submission.csv')\n",
    "end = time.time()\n",
    "print(\"Time taken to read: \",(begin-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca4a11",
   "metadata": {},
   "source": [
    "#### We see that dask reads the fastest with 0.0100 seconds followed by Modlin and Ray with and the least being Pandas with 99.3447 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5e597",
   "metadata": {},
   "source": [
    "## Validation on Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31168390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/lr7tn3dj3jb6ltvh3_h48b8c0000gn/T/ipykernel_8702/378534539.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pandas_data.columns= pandas_data.columns.str.replace('[#,@,&]','')\n"
     ]
    }
   ],
   "source": [
    "pandas_data.columns= pandas_data.columns.str.replace('[#,@,&]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5bed77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_data.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5a26f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befca987",
   "metadata": {},
   "source": [
    "### Creating  YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1008977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.py\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.load(stream, Loader=yaml.Loader)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6b823",
   "metadata": {},
   "source": [
    "### Method for Validating number of columns and column name of ingested file with YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65f19472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def col_header_val(df,table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: re.sub(r'\\W+', '_', x), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c1666",
   "metadata": {},
   "source": [
    "### Creating a YAML file and writing the column name in YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5fae815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file_2.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file_2.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: Rate\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - Survived\n",
    "    - PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8b89cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'file',\n",
       " 'file_name': 'Rate',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['Survived', 'PassengerId']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('file_2.yaml', 'r') as file:\n",
    "\n",
    "    yaml_content = yaml.load(file, Loader=yaml.FullLoader)\n",
    "yaml_content    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a660fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujunwafatima/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3369: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('gender_submission.csv',yaml_content['inbound_delimiter'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ea7b8",
   "metadata": {},
   "source": [
    "### Validating number of columns and column name of ingested file with YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3096a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "col_header_val(df,yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f37b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['passengerid', 'survived'], dtype='object')\n",
      "columns of YAML are: ['Survived', 'PassengerId']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,yaml_content['columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c371fd3",
   "metadata": {},
   "source": [
    "### Writing csv in gz format in pipe separated text file (|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6eb22f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ujunwafatima/Desktop/Data Glacier Assignments/Week6/gender_submission.csv.gz/0.part']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = dask.read_csv('gender_submission.csv',delimiter=',')\n",
    "\n",
    "\n",
    "df.to_csv('gender_submission.csv.gz',\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True,\n",
    "          line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520eaa3",
   "metadata": {},
   "source": [
    "### Summary of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9361173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.part\n"
     ]
    }
   ],
   "source": [
    "# no of files\n",
    "no_of_files = os.listdir('/Users/ujunwafatima/Desktop/Data Glacier Assignments/Week6/gender_submission.csv.gz/')\n",
    "for file in no_of_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6886ede9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of the gz format folder\n",
    "os.path.getsize('/Users/ujunwafatima/Desktop/Data Glacier Assignments/Week6/gender_submission.csv.gz/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
